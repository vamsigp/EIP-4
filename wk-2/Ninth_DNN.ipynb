{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ninth_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsigp/EIP-4/blob/master/wk-2/Ninth_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8p6Pm97Fnpl",
        "colab_type": "text"
      },
      "source": [
        "**Assignment - 2**\n",
        "\n",
        "Design a CNN model to solve MNIST digits dataset\n",
        "\n",
        "Constraints - \n",
        "1.   99.4% Accuracy\n",
        "2.   < 15k Parameters\n",
        "3. <= 20 epochs\n",
        "4. no Fully connected Layer\n",
        "5. No biases should be used\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "outputId": "3c08e04e-71b2-4bf8-8c4f-580c8feb3ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "3a92e8a3-71fd-4743-bc66-0a828ca14066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m635HY-4HIRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_image_id = np.random.randint(low=0, high=len(X_train), dtype='int64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "2269333a-adb9-4e9d-852c-f68c06694062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[random_image_id], cmap='gray')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e79bd8c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "222b1d8b-2062-49e9-9b3e-d7d3f25c2545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "888ac82f-0102-4837-f031-62dd46aec96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx0NHxoCHclX",
        "colab_type": "text"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhjJH_8QHe-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD09mvt1HrkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(16, 3, activation='relu', use_bias=False,input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(32, 3, activation='relu', use_bias=False)) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(10, 1, activation='relu', use_bias=False)) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "\n",
        "model.add(Conv2D(16, 3, activation='relu', use_bias=False)) #9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Conv2D(15, 3, activation='relu', use_bias=False)) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Conv2D(14, 3, activation='relu', use_bias=False)) #5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Conv2D(13, 3, activation='relu', use_bias=False)) #3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Conv2D(10, 4, use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6TH8oOQqeQP",
        "colab_type": "code",
        "outputId": "4001e649-598a-4ea0-90f5-47a8ccd46351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 24, 24, 10)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 10, 10, 16)        1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 15)          2160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 8, 8, 15)          60        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 8, 8, 15)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 14)          1890      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 6, 6, 14)          56        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 6, 6, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 13)          1638      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 4, 4, 13)          52        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 4, 4, 13)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,744\n",
            "Trainable params: 14,512\n",
            "Non-trainable params: 232\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQkSvGbdqfTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.32 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0rG4ky4rDgC",
        "colab_type": "code",
        "outputId": "2776ce1c-29d0-407a-9846-dfd300e30784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), \n",
        "          callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.5273 - acc: 0.8537 - val_loss: 0.1192 - val_acc: 0.9769\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022727273.\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.2586 - acc: 0.9234 - val_loss: 0.0586 - val_acc: 0.9861\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018292683.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.2041 - acc: 0.9378 - val_loss: 0.0591 - val_acc: 0.9861\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015306122.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1742 - acc: 0.9458 - val_loss: 0.0464 - val_acc: 0.9884\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013157895.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1584 - acc: 0.9475 - val_loss: 0.0382 - val_acc: 0.9907\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011538462.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1450 - acc: 0.9487 - val_loss: 0.0305 - val_acc: 0.9926\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010273973.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1331 - acc: 0.9525 - val_loss: 0.0271 - val_acc: 0.9929\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009259259.\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1265 - acc: 0.9527 - val_loss: 0.0298 - val_acc: 0.9915\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008426966.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1228 - acc: 0.9531 - val_loss: 0.0314 - val_acc: 0.9916\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007731959.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1164 - acc: 0.9541 - val_loss: 0.0261 - val_acc: 0.9925\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007142857.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1136 - acc: 0.9538 - val_loss: 0.0285 - val_acc: 0.9924\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0006637168.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1097 - acc: 0.9561 - val_loss: 0.0240 - val_acc: 0.9933\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006198347.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1044 - acc: 0.9572 - val_loss: 0.0225 - val_acc: 0.9940\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005813953.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1039 - acc: 0.9558 - val_loss: 0.0204 - val_acc: 0.9941\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005474453.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1033 - acc: 0.9563 - val_loss: 0.0213 - val_acc: 0.9940\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005172414.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1036 - acc: 0.9549 - val_loss: 0.0229 - val_acc: 0.9941\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0004901961.\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1000 - acc: 0.9573 - val_loss: 0.0205 - val_acc: 0.9944\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004658385.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0958 - acc: 0.9574 - val_loss: 0.0219 - val_acc: 0.9947\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.000443787.\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0967 - acc: 0.9576 - val_loss: 0.0200 - val_acc: 0.9945\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0004237288.\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0947 - acc: 0.9579 - val_loss: 0.0211 - val_acc: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e20038be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Yeo0pQrHWD",
        "colab_type": "code",
        "outputId": "c51b8a57-ab76-410d-bf0e-48d720024e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.021071910318639128, 0.9941]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga_Wh7M-uenC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Tbrg9dnuoZw",
        "colab_type": "text"
      },
      "source": [
        "### Using Global Average Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANcB-PtPvDTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import AveragePooling2D, GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBkS2eHRusZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation\n",
        "model_ga = Sequential()\n",
        " \n",
        "model_ga.add(Conv2D(16, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model_ga.add(BatchNormalization())\n",
        "model_ga.add(Dropout(0.1))\n",
        "\n",
        "model_ga.add(Conv2D(32, 3, activation='relu')) #24\n",
        "model_ga.add(BatchNormalization())\n",
        "model_ga.add(Dropout(0.1))\n",
        "\n",
        "model_ga.add(Conv2D(10, 1, activation='relu')) #22\n",
        "\n",
        "model_ga.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "\n",
        "model_ga.add(Conv2D(16, 3, activation='relu')) #9\n",
        "model_ga.add(BatchNormalization())\n",
        "model_ga.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_ga.add(Conv2D(14, 3, activation='relu')) #7\n",
        "model_ga.add(BatchNormalization())\n",
        "model_ga.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_ga.add(Conv2D(14, 3, activation='relu')) #5\n",
        "model_ga.add(BatchNormalization())\n",
        "model_ga.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_ga.add(Conv2D(12, 3, activation='relu')) #3\n",
        "model_ga.add(BatchNormalization())\n",
        "model_ga.add(Dropout(0.1))\n",
        "\n",
        "# model.add(Conv2D(10, 4))\n",
        "model_ga.add(AveragePooling2D())\n",
        "\n",
        "\n",
        "# model_ga.add(Flatten())\n",
        "model_ga.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6iofMxBx6cD",
        "colab_type": "code",
        "outputId": "59f91001-1b73-4729-8fb5-4044ca846c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model_ga.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_54 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 8, 8, 14)          2030      \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 8, 8, 14)          56        \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 8, 8, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 6, 6, 14)          1778      \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 6, 6, 14)          56        \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 6, 6, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 4, 4, 12)          1524      \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 4, 4, 12)          48        \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 4, 4, 12)          0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 2, 2, 12)          0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2, 2, 12)          0         \n",
            "=================================================================\n",
            "Total params: 12,334\n",
            "Trainable params: 12,126\n",
            "Non-trainable params: 208\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC7czFAzvoau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.322 * epoch), 10)\n",
        "\n",
        "model_ga.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25F9SUOwv4FK",
        "colab_type": "code",
        "outputId": "c4951075-cb40-46f1-e68e-2cbde6fb1ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model_ga.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), \n",
        "          callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8b634da88dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ga.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), \n\u001b[0;32m----> 2\u001b[0;31m           callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_5 to have 4 dimensions, but got array with shape (60000, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz3np-6Bv8kH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}