{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Cifar10_resnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsigp/EIP-4/blob/master/wk-4/Assignment-B/Cifar10_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFsdKCG_7fu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import keras\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvqJp6BR7fvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePjpAn_37fvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SeparableConv2D, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkBZsR9Y7fva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  x_train.shape\n",
        "num_test, _, _, _ =  x_test.shape\n",
        "num_classes = len(np.unique(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qGK58RY7fvj",
        "colab_type": "code",
        "outputId": "265d5105-3b2e-4fb1-fef1-055c8a10d886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    idx = np.where(y_train[:]==i)[0]\n",
        "    features_idx = x_train[idx,::]\n",
        "    img_num = np.random.randint(features_idx.shape[0])\n",
        "    im = features_idx[img_num]\n",
        "    ax.set_title(class_names[i])\n",
        "    plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAADECAYAAAD9PXphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x216 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv8j6WfS7fvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ99a0047fvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTplWcXn7fv5",
        "colab_type": "text"
      },
      "source": [
        "## Base ResnetModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf63hOid7fv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2QFRE5J7fwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj-zj7_i7fwK",
        "colab_type": "code",
        "outputId": "31390362-ef3d-4e9b-87ae-44266c36cc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJzvmAtY7fwZ",
        "colab_type": "code",
        "outputId": "d54631c3-ccd4-49c4-a639-855db9b3f4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWZuAtGO7fwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzQkZpA97fwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfi0gOwS7fws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20GqZMwr7fwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYYElcnI7fw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY_YeCSa7fw9",
        "colab_type": "code",
        "outputId": "2a05ea79-9c7c-4d8d-9e67-0d72d21564c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1osGNaNm7fxD",
        "colab_type": "code",
        "outputId": "774f07cb-548f-46c7-f6aa-f4f922b850dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooSqJny07fxK",
        "colab_type": "code",
        "outputId": "db683859-8f19-42a5-f201-4361927ce83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model_type)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet20v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfbETS1B7fxP",
        "colab_type": "code",
        "outputId": "06f27f24-d6c2-4aa9-c0b1-f9073e712866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYvQ1b87fxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahwgxtXt7fxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NYwno3O7fxh",
        "colab_type": "code",
        "outputId": "991a3f44-7ab6-489a-b332-6dccf253c257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_augmentation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3weMjIG7fxo",
        "colab_type": "code",
        "outputId": "83c76a0e-dac8-48c7-e911-20b443db46b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 50s 129ms/step - loss: 1.6430 - acc: 0.4611 - val_loss: 1.9139 - val_acc: 0.4188\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.41880, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 1.2667 - acc: 0.6001 - val_loss: 1.6973 - val_acc: 0.4801\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.41880 to 0.48010, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 1.0901 - acc: 0.6690 - val_loss: 1.3626 - val_acc: 0.6003\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.48010 to 0.60030, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.9649 - acc: 0.7143 - val_loss: 1.3743 - val_acc: 0.6105\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.60030 to 0.61050, saving model to /content/saved_models/cifar10_ResNet20v1_model.004.h5\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.8785 - acc: 0.7438 - val_loss: 1.0432 - val_acc: 0.6932\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.61050 to 0.69320, saving model to /content/saved_models/cifar10_ResNet20v1_model.005.h5\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.8183 - acc: 0.7659 - val_loss: 0.8498 - val_acc: 0.7542\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.69320 to 0.75420, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.7701 - acc: 0.7854 - val_loss: 1.0707 - val_acc: 0.6998\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.75420\n",
            "Epoch 8/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.7311 - acc: 0.7960 - val_loss: 0.9248 - val_acc: 0.7393\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.75420\n",
            "Epoch 9/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.6960 - acc: 0.8109 - val_loss: 1.1602 - val_acc: 0.6904\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.75420\n",
            "Epoch 10/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.6686 - acc: 0.8165 - val_loss: 1.1860 - val_acc: 0.6897\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75420\n",
            "Epoch 11/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 104ms/step - loss: 0.6529 - acc: 0.8236 - val_loss: 0.9333 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.75420\n",
            "Epoch 12/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.6265 - acc: 0.8346 - val_loss: 1.0185 - val_acc: 0.7351\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.75420\n",
            "Epoch 13/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.6118 - acc: 0.8378 - val_loss: 0.9024 - val_acc: 0.7490\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.75420\n",
            "Epoch 14/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5880 - acc: 0.8453 - val_loss: 0.9857 - val_acc: 0.7335\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.75420\n",
            "Epoch 15/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5779 - acc: 0.8503 - val_loss: 0.8719 - val_acc: 0.7618\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.75420 to 0.76180, saving model to /content/saved_models/cifar10_ResNet20v1_model.015.h5\n",
            "Epoch 16/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5730 - acc: 0.8524 - val_loss: 0.7161 - val_acc: 0.8077\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.76180 to 0.80770, saving model to /content/saved_models/cifar10_ResNet20v1_model.016.h5\n",
            "Epoch 17/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5502 - acc: 0.8596 - val_loss: 0.9533 - val_acc: 0.7511\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80770\n",
            "Epoch 18/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5422 - acc: 0.8618 - val_loss: 0.6922 - val_acc: 0.8219\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.80770 to 0.82190, saving model to /content/saved_models/cifar10_ResNet20v1_model.018.h5\n",
            "Epoch 19/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.5327 - acc: 0.8654 - val_loss: 0.7709 - val_acc: 0.7939\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.82190\n",
            "Epoch 20/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5203 - acc: 0.8711 - val_loss: 0.6807 - val_acc: 0.8230\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.82190 to 0.82300, saving model to /content/saved_models/cifar10_ResNet20v1_model.020.h5\n",
            "Epoch 21/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5128 - acc: 0.8733 - val_loss: 0.8591 - val_acc: 0.7813\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.82300\n",
            "Epoch 22/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.5052 - acc: 0.8756 - val_loss: 0.7460 - val_acc: 0.8009\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.82300\n",
            "Epoch 23/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.4963 - acc: 0.8799 - val_loss: 0.7301 - val_acc: 0.8135\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.82300\n",
            "Epoch 24/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.4886 - acc: 0.8814 - val_loss: 0.7051 - val_acc: 0.8171\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.82300\n",
            "Epoch 25/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4829 - acc: 0.8846 - val_loss: 1.0808 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.82300\n",
            "Epoch 26/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4748 - acc: 0.8867 - val_loss: 0.8623 - val_acc: 0.7757\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.82300\n",
            "Epoch 27/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4701 - acc: 0.8875 - val_loss: 0.7797 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.82300\n",
            "Epoch 28/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4671 - acc: 0.8886 - val_loss: 0.7302 - val_acc: 0.8107\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.82300\n",
            "Epoch 29/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4571 - acc: 0.8933 - val_loss: 0.8183 - val_acc: 0.7889\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.82300\n",
            "Epoch 30/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4563 - acc: 0.8931 - val_loss: 0.7725 - val_acc: 0.8031\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.82300\n",
            "Epoch 31/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.4484 - acc: 0.8955 - val_loss: 0.7133 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.82300\n",
            "Epoch 32/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.4460 - acc: 0.8979 - val_loss: 0.8681 - val_acc: 0.7891\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.82300\n",
            "Epoch 33/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4316 - acc: 0.9036 - val_loss: 0.8456 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.82300\n",
            "Epoch 34/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.4390 - acc: 0.9006 - val_loss: 0.6911 - val_acc: 0.8325\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.82300 to 0.83250, saving model to /content/saved_models/cifar10_ResNet20v1_model.034.h5\n",
            "Epoch 35/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.4312 - acc: 0.9015 - val_loss: 0.8322 - val_acc: 0.7986\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.83250\n",
            "Epoch 36/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4273 - acc: 0.9042 - val_loss: 0.7801 - val_acc: 0.8112\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.83250\n",
            "Epoch 37/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4287 - acc: 0.9051 - val_loss: 0.6992 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.83250\n",
            "Epoch 38/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4224 - acc: 0.9062 - val_loss: 0.7038 - val_acc: 0.8353\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.83250 to 0.83530, saving model to /content/saved_models/cifar10_ResNet20v1_model.038.h5\n",
            "Epoch 39/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4175 - acc: 0.9077 - val_loss: 0.6646 - val_acc: 0.8357\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.83530 to 0.83570, saving model to /content/saved_models/cifar10_ResNet20v1_model.039.h5\n",
            "Epoch 40/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4163 - acc: 0.9078 - val_loss: 0.6656 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.83570 to 0.83940, saving model to /content/saved_models/cifar10_ResNet20v1_model.040.h5\n",
            "Epoch 41/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4160 - acc: 0.9083 - val_loss: 0.7014 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.83940\n",
            "Epoch 42/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.4135 - acc: 0.9104 - val_loss: 0.8549 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.83940\n",
            "Epoch 43/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.4104 - acc: 0.9121 - val_loss: 0.7818 - val_acc: 0.8086\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.83940\n",
            "Epoch 44/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.4059 - acc: 0.9120 - val_loss: 0.7396 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.83940\n",
            "Epoch 45/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.4057 - acc: 0.9125 - val_loss: 0.7291 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.83940\n",
            "Epoch 46/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.3990 - acc: 0.9144 - val_loss: 0.7864 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.83940\n",
            "Epoch 47/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.3975 - acc: 0.9167 - val_loss: 0.7456 - val_acc: 0.8238\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.83940\n",
            "Epoch 48/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.4015 - acc: 0.9140 - val_loss: 0.6347 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.83940 to 0.84930, saving model to /content/saved_models/cifar10_ResNet20v1_model.048.h5\n",
            "Epoch 49/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 0.3955 - acc: 0.9160 - val_loss: 0.8083 - val_acc: 0.8112\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.84930\n",
            "Epoch 50/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.3982 - acc: 0.9153 - val_loss: 0.6116 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.84930 to 0.85200, saving model to /content/saved_models/cifar10_ResNet20v1_model.050.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SenmQlD7fxx",
        "colab_type": "code",
        "outputId": "8063fbf6-c1b0-4b7e-b747-206c7271c1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 201us/step\n",
            "Test loss: 0.611604206085205\n",
            "Test accuracy: 0.852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5hdNnySEUUd",
        "colab_type": "text"
      },
      "source": [
        "#### Base accuracy = 85.2 at end of 50 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjrCUO-oERPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}